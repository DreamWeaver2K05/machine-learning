# -*- coding: utf-8 -*-
"""Federatedlearning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SrKAw-AD7wcCQ58PVyRb1GWDNEds1Xgt
"""

pip install phe

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
# %matplotlib inline
from phe import paillier

filepath="/content/smoking.csv"
data=pd.read_csv(filepath,on_bad_lines='skip')

data.head()

data=data.drop("ID",axis=1)
data.head()

#Handling missing values
data.isna().sum() #there are 201 datas with nan data, remove them

data=data.dropna()

shuffled_data = data.sample(frac=1, random_state=42)

shuffled_data.shape

shuffled_data.isna().sum()

shuffled_data.dtypes

#Separate features & label
xdata=shuffled_data.drop("smoking",axis=1)
ydata=shuffled_data["smoking"]

from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer

catgo=['gender','oral','tartar']
onehot= OneHotEncoder()
trans= ColumnTransformer([('one_hot',
                          onehot,
                          catgo)],
                        remainder='passthrough')

xdata=trans.fit_transform(xdata)
xdata

xdata=pd.DataFrame(xdata)

xdata.head()

ydata.head()

pd.DataFrame(xdata)

x=[0]*5
y=[0]*5
x[0]=xdata[:10000]
y[0]=ydata[:10000]
x[1]=xdata[10000:20000]
y[1]=ydata[10000:20000]
x[2]=xdata[20000:30000]
y[2]=ydata[20000:30000]
x[3]=xdata[30000:40000]
y[3]=ydata[30000:40000]
x[4]=xdata[40000:50000]
y[4]=ydata[40000:50000]

shuffled_data["smoking"].value_counts()[0], shuffled_data["smoking"].value_counts()[1]

x[0].shape,y[0].shape

#Since dataset is imbalance , assign class weights
c_weights = {0: 1., 1: 2.}

def train_model(model,x,y):
  xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2,random_state=42,stratify=y)
  return xtrain,xtest,ytrain,ytest

def create_model(input_dim):
  model=tf.keras.Sequential(
      [
          tf.keras.layers.Input(shape=(input_dim,)),
          tf.keras.layers.Dense(16,activation='relu'),
          tf.keras.layers.Dropout(0.3),
          tf.keras.layers.Dense(8,activation='relu'),
          tf.keras.layers.Dropout(0.3),
          tf.keras.layers.Dense(1,activation='sigmoid')
      ]
  )
  return model

def compile_model(model):
  optimizer = tf.keras.optimizers.SGD(learning_rate=0.0001)
  model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])
  return model

def fit_model(model,x,y,num_epochs,g_l_model='l'):
  model.fit(x,y,epochs=num_epochs,verbose=0,class_weight=c_weights)
  if(g_l_model=='g'):
    print("global model is created & trained")
  elif(g_l_model=='l'):
    print(f"model {i} is created & trained")
  else:
    pass
  return model

def evaluate_model(model,x,y):
  loss,acc=model.evaluate(x,y,verbose=0)
  print("Loss:",loss,"Accuracy:",acc)
  return acc

input_dim = xdata.shape[1]

model=[None]*5
xtrain=[0]*5
xtest=[0]*5
ytrain=[0]*5
ytest=[0]*5
l_yprobs_bfr=[None]*5
l_yprobs_pos_bfr=[None]*5
l_yprobs_aft=[None]*5
l_yprobs_pos_aft=[None]*5
acc=[[0]*16 for _ in range(5)]  # 5 models, 16 iterations (index 0 to 15)
gacc=[None]*16

def setWeight_train_localModel(model,gb_weights,xtrain,ytrain,xtest,ytest):
  model.set_weights(gb_weights)
  model=fit_model(model,xtrain,ytrain,5,'r')
  acc=evaluate_model(model,xtest,ytest)
  return model,acc

def setWeight_train_globalModel(global_model,lm_weights,gxtest,gytest):
  global_model.set_weights(lm_weights)
  global_model=fit_model(global_model,gxtrain,gytrain,5,'r')
  acc=evaluate_model(global_model,gxtest,gytest)
  return global_model,acc

pip install tenseal

import tenseal as ts
import numpy as np

# Create TenSEAL encryption context
def create_lm_context():
    context = ts.context(
        scheme=ts.SCHEME_TYPE.CKKS,
        poly_modulus_degree=8192,
        coeff_mod_bit_sizes=[60, 40, 40, 60]
    )
    context.global_scale = 2**40
    return context

# Encrypt weights while preserving original shape
def encrypt_batch(weights, context):
    shape = weights.shape  # Store shape
    encrypted_vector = ts.ckks_vector(context, weights.flatten().tolist())  # Encrypt as a vector
    return encrypted_vector, shape  # Return encrypted data + shape

# Encrypt all model weights
def get_encrypted_lm_weights(models, context):
    encrypted_model_weights = []
    for m in models:
        encrypted_weights = []
        for w in m.get_weights():
            encrypted_w, shape = encrypt_batch(w, context)  # Encrypt + store shape
            encrypted_weights.append((encrypted_w, shape))  # Store as tuple
        encrypted_model_weights.append(encrypted_weights)
    return encrypted_model_weights  # List of encrypted model weights for all clients

# Perform Secure Aggregation on Encrypted Weights
def aggregate_encrypted_weights(encrypted_models):
    num_models = len(encrypted_models)
    aggregated_weights = []

    # Loop through each weight layer
    for layer_idx in range(len(encrypted_models[0])):  # Assume all models have same structure
        sum_encrypted = encrypted_models[0][layer_idx][0]  # Start with first model's encrypted weight
        shape = encrypted_models[0][layer_idx][1]  # Store shape

        # Sum encrypted weights from all models
        for model_idx in range(1, num_models):
            sum_encrypted += encrypted_models[model_idx][layer_idx][0]  # Homomorphic addition

        # Compute Encrypted Average
        avg_encrypted = sum_encrypted * (1.0 / num_models)  # Homomorphic division

        # Store aggregated encrypted weight
        aggregated_weights.append((avg_encrypted, shape))

    return aggregated_weights  # Returns final aggregated encrypted weights

# Decrypt while restoring original shape
def decrypt_batch(encrypted_w, shape):
    decrypted_w = np.array(encrypted_w.decrypt())  # Decrypt
    return decrypted_w.reshape(shape)  # Reshape to original form

def get_decrypted_lm_weights(encrypted_weights):
    decrypted_model_weights = []
    for enc_w, shape in encrypted_weights:
        decrypted_w = decrypt_batch(enc_w, shape)  # Decrypt + reshape
        decrypted_model_weights.append(decrypted_w)
    return decrypted_model_weights

import tenseal as ts
import numpy as np

# Create TenSEAL encryption context
def create_gm_context():
    context = ts.context(
        scheme=ts.SCHEME_TYPE.CKKS,
        poly_modulus_degree=8192,
        coeff_mod_bit_sizes=[60, 40, 40, 60]
    )
    context.global_scale = 2**40
    return context

# Encrypt the weights of a single model
def get_encrypted_gm_weights(model, context):
    encrypted_weights = []
    for w in model.get_weights():
        shape = w.shape  # Store shape for reconstruction
        encrypted_w = ts.ckks_vector(context, w.flatten().tolist())  # Encrypt flattened weights
        encrypted_weights.append((encrypted_w, shape))  # Store as tuple (encrypted_vector, shape)
    return encrypted_weights

# Decrypt the encrypted model weights
def get_decrypted_gm_weights(encrypted_weights):
    decrypted_weights = []
    for enc_w, shape in encrypted_weights:
        decrypted_w = np.array(enc_w.decrypt())  # Decrypt
        decrypted_weights.append(decrypted_w.reshape(shape))  # Reshape to original form
    return decrypted_weights

for i in range (5):
  model[i]=create_model(input_dim)
  xtrain[i],xtest[i],ytrain[i],ytest[i]=train_model(model[i],x[i],y[i])
  model[i]=compile_model(model[i])
  model[i]=fit_model(model[i],xtrain[i],ytrain[i],5)

global_model=create_model(input_dim)
gxtrain,gxtest,gytrain,gytest=train_model(global_model,xdata,ydata)
global_model=compile_model(global_model)
global_model=fit_model(global_model,gxtrain,gytrain,5,'g')

#predict gives the probabilities for class 1
#Values before training with updated weights
g_yprobs_bfr=global_model.predict(gxtest)
for i in range(5):
  l_yprobs_bfr[i]=model[i].predict(xtest[i])

import time
np.random.seed(45)

print("Before Training with weights:")
print("GLOBAL MODEL")
start=time.time()
evaluate_model(global_model,gxtest,gytest)
end=time.time()
print(f"Time duration: {(end-start)*1000:.2f} ms")

for i in range(5):
    start=time.time()
    print(f"MODEL {i+1}")
    acc[i][0]=evaluate_model(model[i],xtest[i],ytest[i])
    end=time.time()
    print(f"Time duration: {(end-start)*1000:.2f} ms")

print("Testing after training with weights")
for j in range(1,16):
    print(f"\n--- Iteration {j} ---")

    # ---- Local Models Encryption ----
    context=create_lm_context()
    enc_start=time.time()
    en_lm_weights=get_encrypted_lm_weights(model,context)
    enc_end=time.time()
    local_models_encryption_time=(enc_end-enc_start)*1000

    # ---- Aggregation + Decryption ----
    agg_start=time.time()
    agr_en_weights=aggregate_encrypted_weights(en_lm_weights)
    lm_weights=get_decrypted_lm_weights(agr_en_weights)
    agg_end=time.time()
    aggregation_time=(agg_end-agg_start)*1000

    # ---- Global Model Training ----
    global_train_start=time.time()
    global_model,gacc[j]=setWeight_train_globalModel(global_model,lm_weights,gxtest,gytest)
    global_train_end=time.time()
    global_train_time=(global_train_end-global_train_start) * 1000

    # ---- Global Model Encryption ----
    gm_enc_start=time.time()
    context=create_gm_context()
    en_gm_weights=get_encrypted_gm_weights(global_model,context)
    gm_enc_end=time.time()
    global_model_encryption_time=(gm_enc_end-gm_enc_start)*1000

    # ---- Global Model Decryption ----
    gm_dec_start=time.time()
    gm_weights=get_decrypted_gm_weights(en_gm_weights)
    gm_dec_end=time.time()
    global_model_decryption_time=(gm_dec_end-gm_dec_start)*1000

    # âœ… Print Global Model Stats in requested format
    print(f"\nGLOBAL MODEL:")
    print(f"Accuracy: {gacc[j]:.4f}")
    print(f"Training Time: {global_train_time:.2f} ms")
    print(f"Encryption Time: {global_model_encryption_time:.2f} ms")
    print(f"Decryption Time: {global_model_decryption_time:.2f} ms")

    # ---- Local Model Training ----
    print("\nLOCAL MODELS:")
    for i in range(5):
    # ---- Local Model Encryption ----
      context = create_lm_context()  # Create separate context per model if needed
      enc_start = time.time()
      en_lm_weights = get_encrypted_lm_weights([model[i]], context)  # Encrypt only model[i]
      enc_end = time.time()
      model_enc_time = (enc_end - enc_start) * 1000

    # ---- Local Model Decryption ----
    # Here, decrypt the aggregated global weights for this model
      dec_start = time.time()
      gm_weights = get_decrypted_gm_weights(en_gm_weights)  # This could still be shared if global model is common
      dec_end = time.time()
      model_dec_time = (dec_end - dec_start) * 1000

    # ---- Local Training ----
      local_train_start = time.time()
      model[i], acc[i][j] = setWeight_train_localModel(model[i], gm_weights, xtrain[i], ytrain[i], xtest[i], ytest[i])
      local_train_end = time.time()
      local_train_time = (local_train_end - local_train_start) * 1000

    # âœ… Print Local Model Stats
      print(f"\nMODEL {i+1}:")
      print(f"Accuracy: {acc[i][j]:.4f}")
      print(f"Training Time: {local_train_time:.2f} ms")
      print(f"Encryption Time: {model_enc_time:.2f} ms")
      print(f"Decryption Time: {model_dec_time:.2f} ms")

#probabilities after training with updated weights
g_yprobs_aft=global_model.predict(gxtest)

for i in range(5):
  l_yprobs_aft[i]=model[i].predict(xtest[i])

"""##ROC CURVE:"""

import matplotlib.pyplot as plt

def plot_roc_curve(fpr,tpr,i=0):
    #PLot roc curve
    plt.plot(fpr,tpr,color='orange',label='ROC')
    #Plot line with no predictive power(baseline)
    plt.plot([0,1],[0,1],color='darkblue',linestyle='--',label='Guessing')

    #Customize the plot
    plt.xlabel('False positive rate(fpr)')
    plt.ylabel('True positive rates(tpr)')
    plt.legend()
    if(i!=0):
      plt.title(f'ROC for local model {i}')
      plt.savefig(f"LM_ROCplot{i}.png", dpi=300, bbox_inches='tight')
    else:
      plt.title('ROC for global model')
      plt.savefig(f"GM_ROCplot.png", dpi=300, bbox_inches='tight')
    plt.show()

"""###BEFORE TRAINING WITH WEIGHTS:"""

from sklearn.metrics import roc_curve

for i in range(5):
  plt.figure(figsize=(8, 5))
  fpr,tpr,thresholds=roc_curve(ytest[i],l_yprobs_bfr[i])
  plot_roc_curve(fpr,tpr,i+1)

plt.figure(figsize=(8, 5))
fpr,tpr,thresholds=roc_curve(gytest,g_yprobs_bfr)
plot_roc_curve(fpr,tpr)

"""###AFTER TRAINING WITH WEIGHTS:"""

for i in range(5):
  plt.figure(figsize=(8, 5))
  fpr,tpr,thresholds=roc_curve(ytest[i],l_yprobs_aft[i])
  plot_roc_curve(fpr,tpr,i+1)

plt.figure(figsize=(8, 5))
fpr,tpr,thresholds=roc_curve(gytest,g_yprobs_aft)
plot_roc_curve(fpr,tpr)

"""ACCURACY GRAPH OF EACH MODELS:"""

def plot_acc_graph(acc_array,i=7):
    x_values = range(len (acc_array))
    plt.figure(figsize=(8, 5))
    plt.xlabel("Iteration")
    plt.ylabel("Accuracy")
    plt.legend()
    plt.grid(True)
    if(i==7):
      plt.plot(x_values,acc_array,marker='o',linestyle='-',label=f'Global Model')
      plt.title(f"Training Progress - Global Model")
      plt.savefig("GM_ACCplot.png",dpi=300,bbox_inches='tight')
    else:
      plt.plot(x_values,acc_array,marker='o',linestyle='-',label=f'Model{i}')
      plt.title(f"Training Progress - Local Model {i+1}")
      plt.savefig(f"LM{i+1}_ACCplot.png",dpi=300,bbox_inches='tight')
    plt.show()

#Creating accuracy graph
#Local models:
for i in range(5):
    plot_acc_graph(acc[i],i)

#Global model
plot_acc_graph(gacc,7) #7-identifying it as a global model

plt.figure(figsize=(10,6))
for i in range(5):
    x_values=range(len(acc[i]))
    plt.plot(x_values,acc[i],marker='o',linestyle='-',label=f'Model {i+1}')

plt.xlabel("Iteration")
plt.ylabel("Accuracy")
plt.title("Training Progress of Local Models")
plt.legend()
plt.grid(True)
plt.savefig("Acc_plot_lm.png",dpi=300,bbox_inches='tight')
plt.show()

